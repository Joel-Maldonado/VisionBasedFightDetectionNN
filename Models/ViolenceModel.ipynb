{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-07-23T07:58:32.862777Z",
          "iopub.status.busy": "2022-07-23T07:58:32.862388Z",
          "iopub.status.idle": "2022-07-23T07:58:46.239195Z",
          "shell.execute_reply": "2022-07-23T07:58:46.238056Z",
          "shell.execute_reply.started": "2022-07-23T07:58:32.862696Z"
        },
        "id": "-5QrCdp0GV3H"
      },
      "outputs": [],
      "source": [
        "!pip install silence_tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZP1NOsfHYq6"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2022-07-23T07:58:46.244650Z",
          "iopub.status.busy": "2022-07-23T07:58:46.242535Z",
          "iopub.status.idle": "2022-07-23T07:58:51.674459Z",
          "shell.execute_reply": "2022-07-23T07:58:51.673478Z",
          "shell.execute_reply.started": "2022-07-23T07:58:46.244619Z"
        },
        "id": "lWZB4lVqGV3M"
      },
      "outputs": [],
      "source": [
        "from silence_tensorflow import silence_tensorflow\n",
        "silence_tensorflow()\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-07-23T07:58:51.676812Z",
          "iopub.status.busy": "2022-07-23T07:58:51.676106Z",
          "iopub.status.idle": "2022-07-23T07:58:54.448023Z",
          "shell.execute_reply": "2022-07-23T07:58:54.446934Z",
          "shell.execute_reply.started": "2022-07-23T07:58:51.676769Z"
        },
        "id": "VKV6l1HwGV3O"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(tf.config.list_physical_devices())\n",
        "strategy = tf.distribute.MirroredStrategy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2022-07-23T07:58:54.455471Z",
          "iopub.status.busy": "2022-07-23T07:58:54.455092Z",
          "iopub.status.idle": "2022-07-23T07:58:54.468616Z",
          "shell.execute_reply": "2022-07-23T07:58:54.466727Z",
          "shell.execute_reply.started": "2022-07-23T07:58:54.455427Z"
        },
        "id": "qyPjLgboGV3Q"
      },
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "IMG_SIZE = 224\n",
        "N_FRAMES = 20\n",
        "BATCH_SIZE = 4\n",
        "CHANNELS = 1\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "TRAIN_RECORD_DIR = 'Data/violence_video_train.tfrecord'\n",
        "VAL_RECORD_DIR = 'Data/violence_video_val.tfrecord'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2022-07-23T07:58:54.472561Z",
          "iopub.status.busy": "2022-07-23T07:58:54.472277Z",
          "iopub.status.idle": "2022-07-23T07:58:54.481564Z",
          "shell.execute_reply": "2022-07-23T07:58:54.480593Z",
          "shell.execute_reply.started": "2022-07-23T07:58:54.472536Z"
        },
        "id": "ms8nVbGsGV3S"
      },
      "outputs": [],
      "source": [
        "def parse_tfrecord(example):\n",
        "    features = {\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'feature': tf.io.FixedLenFeature([], tf.string)\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, features)\n",
        "    video = tf.io.decode_raw(example['feature'], tf.float32)\n",
        "    video = tf.reshape(video, (N_FRAMES, IMG_SIZE, IMG_SIZE, CHANNELS))\n",
        "    label = tf.cast(example['label'], tf.uint8)\n",
        "    return video, label\n",
        "\n",
        "def preprocess(video, label):\n",
        "    video = video / 255.0\n",
        "    return video, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-07-23T07:58:54.484382Z",
          "iopub.status.busy": "2022-07-23T07:58:54.483571Z",
          "iopub.status.idle": "2022-07-23T07:58:54.682090Z",
          "shell.execute_reply": "2022-07-23T07:58:54.681057Z",
          "shell.execute_reply.started": "2022-07-23T07:58:54.484346Z"
        },
        "id": "vHvMgsfyGV3U"
      },
      "outputs": [],
      "source": [
        "DATASET_SIZE = 2000\n",
        "\n",
        "train_dataset = tf.data.TFRecordDataset(TRAIN_RECORD_DIR)\n",
        "train_dataset = train_dataset.map(parse_tfrecord)\n",
        "train_dataset = train_dataset.map(preprocess)\n",
        "\n",
        "val_dataset = tf.data.TFRecordDataset(VAL_RECORD_DIR)\n",
        "val_dataset = val_dataset.map(parse_tfrecord)\n",
        "val_dataset = val_dataset.map(preprocess)\n",
        "\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1600)\n",
        "val_dataset = val_dataset.shuffle(buffer_size=400)\n",
        "\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "train_dataset = train_dataset.prefetch(AUTOTUNE)\n",
        "val_dataset = val_dataset.prefetch(AUTOTUNE)\n",
        "\n",
        "train_dataset, val_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDe4ZfvC88PE"
      },
      "outputs": [],
      "source": [
        "class RandomFlipVideo(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(RandomFlipVideo, self).__init__()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        if tf.random.uniform(()) > 0.5:\n",
        "            return tf.map_fn(lambda x: tf.image.flip_left_right(x), inputs)\n",
        "        return inputs\n",
        "\n",
        "class RandomRotationVideo(tf.keras.layers.Layer):\n",
        "    def __init__(self, max_rotation=0.3, **kwargs):\n",
        "        super(RandomRotationVideo, self).__init__()\n",
        "        self.max_rotation = max_rotation\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.map_fn(self.rotate, inputs)\n",
        "\n",
        "    def rotate(self, video):\n",
        "        random_factor = self.max_rotation * self.max_rotation * 2 - self.max_rotation\n",
        "        return tfa.image.rotate(video, random_factor)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2022-07-23T07:58:54.684261Z",
          "iopub.status.busy": "2022-07-23T07:58:54.683918Z",
          "iopub.status.idle": "2022-07-23T07:58:54.695921Z",
          "shell.execute_reply": "2022-07-23T07:58:54.694943Z",
          "shell.execute_reply.started": "2022-07-23T07:58:54.684227Z"
        },
        "id": "kEmyHUhyGV3W"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "\n",
        "    NEURONS = 16\n",
        "    DROPOUT = 0.5\n",
        "    N_LAYERS = 1\n",
        "\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    model.add(layers.InputLayer(input_shape=(N_FRAMES, IMG_SIZE, IMG_SIZE, CHANNELS)))\n",
        "    model.add(RandomFlipVideo())\n",
        "    model.add(RandomRotationVideo(0.3))\n",
        "\n",
        "    model.add(layers.ConvLSTM2D(\n",
        "        filters=8, \n",
        "        kernel_size=3,\n",
        "        padding='same'))\n",
        "    model.add(layers.TimeDistributed(layers.Dropout(0.5)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    model.add(layers.Dense(128))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer=tf.keras.optimizers.Nadam(),\n",
        "        metrics=['accuracy'],\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um8caj0VFgtI"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_addons\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow_addons as tfa\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRQzDhuoP1m6"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(30, 7))\n",
        "rows=2\n",
        "columns=10\n",
        "\n",
        "for batch_video, batch_label in val_dataset:\n",
        "    for video, label in zip(batch_video, batch_label):\n",
        "    print(label)\n",
        "\n",
        "    factor = tf.random.uniform(()) * 0.35 * 2 - 0.35\n",
        "    new_vid = tfa.image.rotate(video, factor)\n",
        "\n",
        "    print(video.shape)\n",
        "    print(new_vid.shape)\n",
        "\n",
        "    for i, frame in enumerate(new_vid):\n",
        "        img = tf.cast(frame * 255, np.uint8).numpy()\n",
        "        img = np.reshape(img, (224, 224))\n",
        "        fig.add_subplot(rows, columns, i+1)\n",
        "        plt.imshow(img, 'gray')\n",
        "        plt.axis('off')\n",
        "        plt.title(label.numpy())\n",
        "\n",
        "        break\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-07-23T07:58:54.711985Z",
          "iopub.status.busy": "2022-07-23T07:58:54.711630Z"
        },
        "id": "GXmHqb2dGV3e"
      },
      "outputs": [],
      "source": [
        "early_stopper = tf.keras.callbacks.EarlyStopping('val_accuracy', patience=20, restore_best_weights=True)\n",
        "reduce_lr_on_plataeu = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=5)\n",
        "\n",
        "from datetime import datetime\n",
        "time_date = datetime.now().strftime(\"%I-%M-%p\")\n",
        "\n",
        "check_point = tf.keras.callbacks.ModelCheckpoint(f'Checkpoints/violence_model_{time_date}.h5', save_best_only=True)\n",
        "\n",
        "with strategy.scope():\n",
        "    model = create_model()\n",
        "\n",
        "history = model.fit(train_dataset, \n",
        "                    validation_data=val_dataset, \n",
        "                    epochs=5, \n",
        "                    callbacks=[check_point, early_stopper, reduce_lr_on_plataeu, tf.keras.callbacks.TensorBoard(\"tb_logs\")], \n",
        "                    use_multiprocessing=True, \n",
        "                    workers=16,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    )\n",
        "\n",
        "model.save(f'PersonDetection_temp.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(history.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yMnt-ufGV3f"
      },
      "outputs": [],
      "source": [
        "metrics = model.evaluate(val_dataset)\n",
        "metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qVockiPZvRH"
      },
      "outputs": [],
      "source": [
        "model.save(f'Models/Violence_Acc_{metrics[1]}.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnLA61dsGV3h"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model('/content/PersonDetection_temp.h5', custom_objects= {\n",
        "    'RandomFlipVideo': RandomFlipVideo,\n",
        "    'RandomRotationVideo': RandomRotationVideo,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_hKXqWvuH4A"
      },
      "outputs": [],
      "source": [
        "model.evaluate(val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcfk1PE4vUjL"
      },
      "outputs": [],
      "source": [
        "for batch_vids, batch_labels in val_dataset:\n",
        "    for vid, lab in zip(batch_vids, batch_labels):\n",
        "        print(vid)\n",
        "        print(lab)\n",
        "        video = vid\n",
        "        label = lab\n",
        "        break\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmo6nrHVS9Kt"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "KtBzysD_Uim-"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(35, 7))\n",
        "rows = 2\n",
        "cols = 10\n",
        "for i, frame in enumerate(vid):\n",
        "    fig.add_subplot(rows, cols, i+1)\n",
        "    plt.imshow(np.reshape(frame, (224, 224)), cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title(lab.numpy())\n",
        "\n",
        "print(model.predict(tf.expand_dims(vid, 0))[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pb8cN7roUvxw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of violentmodel_(1).ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.0 ('tf')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "6ec0bb9ae87b7607fc0ae2763ef9d353eec02876b1253fae67dd25c70d442a59"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
