{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-07-23T07:58:32.862777Z",
     "iopub.status.busy": "2022-07-23T07:58:32.862388Z",
     "iopub.status.idle": "2022-07-23T07:58:46.239195Z",
     "shell.execute_reply": "2022-07-23T07:58:46.238056Z",
     "shell.execute_reply.started": "2022-07-23T07:58:32.862696Z"
    },
    "id": "-5QrCdp0GV3H",
    "outputId": "4e058692-9f59-4bbf-c95b-fe2e0e3fc9c1"
   },
   "outputs": [],
   "source": [
    "!pip install silence_tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qZP1NOsfHYq6",
    "outputId": "d2d217d1-1365-4ea6-a701-318b472e3b39"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-23T07:58:46.244650Z",
     "iopub.status.busy": "2022-07-23T07:58:46.242535Z",
     "iopub.status.idle": "2022-07-23T07:58:51.674459Z",
     "shell.execute_reply": "2022-07-23T07:58:51.673478Z",
     "shell.execute_reply.started": "2022-07-23T07:58:46.244619Z"
    },
    "id": "lWZB4lVqGV3M"
   },
   "outputs": [],
   "source": [
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-07-23T07:58:51.676812Z",
     "iopub.status.busy": "2022-07-23T07:58:51.676106Z",
     "iopub.status.idle": "2022-07-23T07:58:54.448023Z",
     "shell.execute_reply": "2022-07-23T07:58:54.446934Z",
     "shell.execute_reply.started": "2022-07-23T07:58:51.676769Z"
    },
    "id": "VKV6l1HwGV3O",
    "outputId": "b60fa84d-7ad1-4400-f8c2-18c95ba72d2b"
   },
   "outputs": [],
   "source": [
    "# GPUs\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for gpu in gpus:\n",
    "#   tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "print(tf.config.list_physical_devices())\n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-23T07:58:54.455471Z",
     "iopub.status.busy": "2022-07-23T07:58:54.455092Z",
     "iopub.status.idle": "2022-07-23T07:58:54.468616Z",
     "shell.execute_reply": "2022-07-23T07:58:54.466727Z",
     "shell.execute_reply.started": "2022-07-23T07:58:54.455427Z"
    },
    "id": "qyPjLgboGV3Q"
   },
   "outputs": [],
   "source": [
    "# Random seed to ensure reproducibility\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = 224\n",
    "N_FRAMES = 20\n",
    "BATCH_SIZE = 4\n",
    "CHANNELS = 1\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "TRAIN_RECORD_DIR = 'Data/violence_video_train.tfrecord'\n",
    "VAL_RECORD_DIR = 'Data/violence_video_val.tfrecord'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-23T07:58:54.472561Z",
     "iopub.status.busy": "2022-07-23T07:58:54.472277Z",
     "iopub.status.idle": "2022-07-23T07:58:54.481564Z",
     "shell.execute_reply": "2022-07-23T07:58:54.480593Z",
     "shell.execute_reply.started": "2022-07-23T07:58:54.472536Z"
    },
    "id": "ms8nVbGsGV3S"
   },
   "outputs": [],
   "source": [
    "def parse_tfrecord(example):\n",
    "    features = {\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'feature': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, features)\n",
    "    video = tf.io.decode_raw(example['feature'], tf.float32)\n",
    "    video = tf.reshape(video, (N_FRAMES, IMG_SIZE, IMG_SIZE, CHANNELS))\n",
    "    label = tf.cast(example['label'], tf.uint8)\n",
    "    return video, label\n",
    "\n",
    "def preprocess(video, label):\n",
    "    video = video / 255.0\n",
    "    return video, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-07-23T07:58:54.484382Z",
     "iopub.status.busy": "2022-07-23T07:58:54.483571Z",
     "iopub.status.idle": "2022-07-23T07:58:54.682090Z",
     "shell.execute_reply": "2022-07-23T07:58:54.681057Z",
     "shell.execute_reply.started": "2022-07-23T07:58:54.484346Z"
    },
    "id": "vHvMgsfyGV3U",
    "outputId": "1dfd470b-c5b8-442d-fef2-bdf84138f7a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset element_spec=(TensorSpec(shape=(None, 20, 224, 224, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.uint8, name=None))>,\n",
       " <PrefetchDataset element_spec=(TensorSpec(shape=(None, 20, 224, 224, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.uint8, name=None))>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_SIZE = 2000\n",
    "\n",
    "# train = tf.data.TFRecordDataset(TRAIN_RECORD_DIR)\n",
    "# val = tf.data.TFRecordDataset(VAL_RECORD_DIR)\n",
    "\n",
    "# dataset = train.concatenate(val)\n",
    "# dataset = dataset.map(parse_tfrecord)\n",
    "# dataset = dataset.map(preprocess)\n",
    "# dataset = dataset.shuffle(buffer_size=DATASET_SIZE)\n",
    "\n",
    "\n",
    "# TRAIN_SPLIT = int(0.75 * DATASET_SIZE)\n",
    "# TEST_SPLIT = int(0.15 * DATASET_SIZE)\n",
    "# VAL_SPLIT = int(0.15 * DATASET_SIZE)\n",
    "\n",
    "# train_dataset = dataset.take(TRAIN_SPLIT)\n",
    "# rest_dataset = dataset.skip(TRAIN_SPLIT)\n",
    "# test_dataset = rest_dataset.take(TEST_SPLIT)\n",
    "# val_dataset = rest_dataset.skip(VAL_SPLIT)\n",
    "\n",
    "# train_dataset = train_dataset.shuffle(buffer_size=TRAIN_SPLIT)\n",
    "# # test_dataset = test_dataset.shuffle(buffer_size=TEST_SPLIT)\n",
    "# # val_dataset = val_dataset.shuffle(buffer_size=VAL_SPLIT)\n",
    "\n",
    "# train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "# test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "# val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "# # train_dataset = train_dataset.prefetch(AUTOTUNE)\n",
    "# # val_dataset = val_dataset.prefetch(AUTOTUNE)\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = tf.data.TFRecordDataset(TRAIN_RECORD_DIR)\n",
    "train_dataset = train_dataset.map(parse_tfrecord)\n",
    "train_dataset = train_dataset.map(preprocess)\n",
    "\n",
    "val_dataset = tf.data.TFRecordDataset(VAL_RECORD_DIR)\n",
    "val_dataset = val_dataset.map(parse_tfrecord)\n",
    "val_dataset = val_dataset.map(preprocess)\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1600)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=400)\n",
    "\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.prefetch(AUTOTUNE)\n",
    "val_dataset = val_dataset.prefetch(AUTOTUNE)\n",
    "\n",
    "# train_dataset, val_dataset\n",
    "train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "iDe4ZfvC88PE"
   },
   "outputs": [],
   "source": [
    "class RandomFlipVideo(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RandomFlipVideo, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if tf.random.uniform(()) > 0.5:\n",
    "            return tf.map_fn(lambda x: tf.image.flip_left_right(x), inputs)\n",
    "        return inputs\n",
    "\n",
    "class RandomRotationVideo(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_rotation=0.3, **kwargs):\n",
    "        super(RandomRotationVideo, self).__init__()\n",
    "        self.max_rotation = max_rotation\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.map_fn(self.rotate, inputs)\n",
    "\n",
    "    def rotate(self, video):\n",
    "        random_factor = self.max_rotation * self.max_rotation * 2 - self.max_rotation\n",
    "        return tfa.image.rotate(video, random_factor)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-23T07:58:54.684261Z",
     "iopub.status.busy": "2022-07-23T07:58:54.683918Z",
     "iopub.status.idle": "2022-07-23T07:58:54.695921Z",
     "shell.execute_reply": "2022-07-23T07:58:54.694943Z",
     "shell.execute_reply.started": "2022-07-23T07:58:54.684227Z"
    },
    "id": "kEmyHUhyGV3W"
   },
   "outputs": [],
   "source": [
    "# Model Creation\n",
    "def create_model():\n",
    "\n",
    "    NEURONS = 16\n",
    "    DROPOUT = 0.5\n",
    "    N_LAYERS = 1\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "    model.add(layers.InputLayer(input_shape=(N_FRAMES, IMG_SIZE, IMG_SIZE, CHANNELS)))\n",
    "    model.add(RandomFlipVideo())\n",
    "    model.add(RandomRotationVideo(0.3))\n",
    "\n",
    "    model.add(layers.ConvLSTM2D(\n",
    "        filters=8, \n",
    "        kernel_size=3,\n",
    "        padding='same'))\n",
    "    model.add(layers.TimeDistributed(layers.Dropout(0.5)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(128))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.Nadam(),\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "um8caj0VFgtI",
    "outputId": "b028c2cf-44e3-4e5f-cf46-bf8e145b0c1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /path/redacted/Miniconda/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/path/redacted/Miniconda/envs/tf/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -eras (/path/redacted/Miniconda/envs/tf/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tensorflow_addons in /path/redacted/Miniconda/envs/tf/lib/python3.9/site-packages (0.17.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in /path/redacted/Miniconda/envs/tf/lib/python3.9/site-packages (from tensorflow_addons) (2.13.3)\n",
      "Requirement already satisfied: packaging in /path/redacted/Miniconda/envs/tf/lib/python3.9/site-packages (from tensorflow_addons) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /path/redacted/Miniconda/envs/tf/lib/python3.9/site-packages (from packaging->tensorflow_addons) (3.0.4)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/path/redacted/Miniconda/envs/tf/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_addons\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import cv2\n",
    "import tensorflow_addons as tfa\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "SRQzDhuoP1m6"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (192849513.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [13]\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(label)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# Dataset checking\n",
    "fig = plt.figure(figsize=(30, 7))\n",
    "rows=2\n",
    "columns=10\n",
    "\n",
    "for batch_video, batch_label in val_dataset:\n",
    "    for video, label in zip(batch_video, batch_label):\n",
    "    print(label)\n",
    "\n",
    "    #     layer = tf.keras.layers.RandomRotation(0.05)\n",
    "    #     layer = RandomFlipVideo()\n",
    "    #     layer = RandomRotationVideo(0.05)\n",
    "    #     layer = tfa.image.rotate(0.35)\n",
    "\n",
    "    #     new_vid = layer(batch_video)\n",
    "    factor = tf.random.uniform(()) * 0.35 * 2 - 0.35\n",
    "    #     other = np.random.random() * 0.35\n",
    "    new_vid = tfa.image.rotate(video, factor)\n",
    "\n",
    "    print(video.shape)\n",
    "    print(new_vid.shape)\n",
    "\n",
    "    for i, frame in enumerate(new_vid):\n",
    "        img = tf.cast(frame * 255, np.uint8).numpy()\n",
    "        img = np.reshape(img, (224, 224))\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        plt.imshow(img, 'gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(label.numpy())\n",
    "\n",
    "\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-07-23T07:58:54.711985Z",
     "iopub.status.busy": "2022-07-23T07:58:54.711630Z"
    },
    "id": "GXmHqb2dGV3e",
    "outputId": "e98df5bc-25b0-4819-e693-e6ba9b84e7cc"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/path/redacted/ViolenceModel.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/path/redacted/ViolenceModel.ipynb#ch0000011?line=0'>1</a>\u001b[0m early_stopper \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/path/redacted/ViolenceModel.ipynb#ch0000011?line=1'>2</a>\u001b[0m reduce_lr_on_plataeu \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mReduceLROnPlateau(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/path/redacted/ViolenceModel.ipynb#ch0000011?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatetime\u001b[39;00m \u001b[39mimport\u001b[39;00m datetime\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "early_stopper = tf.keras.callbacks.EarlyStopping('val_accuracy', patience=20, restore_best_weights=True)\n",
    "reduce_lr_on_plataeu = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=5)\n",
    "\n",
    "from datetime import datetime\n",
    "time_date = datetime.now().strftime(\"%I-%M-%p\")\n",
    "\n",
    "check_point = tf.keras.callbacks.ModelCheckpoint(f'Checkpoints/violence_model_{time_date}.h5', save_best_only=True)\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    model = create_model()\n",
    "\n",
    "history = model.fit(train_dataset, \n",
    "                    validation_data=val_dataset, \n",
    "                    epochs=5, \n",
    "                    callbacks=[check_point, early_stopper, reduce_lr_on_plataeu, tf.keras.callbacks.TensorBoard(\"tb_logs\")], \n",
    "                    use_multiprocessing=True, \n",
    "                    workers=16,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    )\n",
    "\n",
    "model.save(f'PersonDetection_temp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/path/redacted/ViolenceModel.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/path/redacted/ViolenceModel.ipynb#ch0000012?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(history\u001b[39m.\u001b[39mhistory)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1yMnt-ufGV3f",
    "outputId": "54e57e69-de26-4cda-abac-d4906fdbbcb3"
   },
   "outputs": [],
   "source": [
    "metrics = model.evaluate(val_dataset)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7qVockiPZvRH"
   },
   "outputs": [],
   "source": [
    "model.save(f'Models/Violence_Acc_{metrics[1]}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AnLA61dsGV3h"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/content/PersonDetection_temp.h5', custom_objects= {\n",
    "    'RandomFlipVideo': RandomFlipVideo,\n",
    "    'RandomRotationVideo': RandomRotationVideo,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w_hKXqWvuH4A",
    "outputId": "938a899d-90de-428c-d297-942ee1b3ecc5"
   },
   "outputs": [],
   "source": [
    "model.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hcfk1PE4vUjL",
    "outputId": "45a6e5dd-8288-4018-fc2b-00dae9a400c0"
   },
   "outputs": [],
   "source": [
    "for batch_vids, batch_labels in val_dataset:\n",
    "    for vid, lab in zip(batch_vids, batch_labels):\n",
    "        print(vid)\n",
    "        print(lab)\n",
    "        video = vid\n",
    "        label = lab\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qmo6nrHVS9Kt"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "id": "KtBzysD_Uim-",
    "outputId": "2d2fe890-ff98-4905-80f7-b528760bfc51"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(35, 7))\n",
    "rows = 2\n",
    "cols = 10\n",
    "for i, frame in enumerate(vid):\n",
    "    fig.add_subplot(rows, cols, i+1)\n",
    "    plt.imshow(np.reshape(frame, (224, 224)), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(lab.numpy())\n",
    "\n",
    "print(model.predict(tf.expand_dims(vid, 0))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pb8cN7roUvxw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of violentmodel_(1).ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.9.0 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "6ec0bb9ae87b7607fc0ae2763ef9d353eec02876b1253fae67dd25c70d442a59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
